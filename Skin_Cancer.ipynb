{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIhvqNOlkIXH"
      },
      "source": [
        "# **Download ISIC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSp-w8HGJajh"
      },
      "outputs": [],
      "source": [
        "! wget https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task3_Training_Input.zip\n",
        "! unzip ISIC2018_Task3_Training_Input.zip\n",
        "! wget https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task3_Validation_Input.zip\n",
        "! unzip ISIC2018_Task3_Validation_Input.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "943VW21vsVTj"
      },
      "source": [
        "# **Classification Libs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtM7F673rqKQ",
        "outputId": "bc23cf6f-087d-45ee-e228-0444b32d6839"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# imports\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import copy\n",
        "import time\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm.auto import tqdm, trange\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from skimage.restoration import denoise_nl_means, estimate_sigma\n",
        "from skimage.metrics import peak_signal_noise_ratio\n",
        "from skimage.util import random_noise\n",
        "\n",
        "# scripts import\n",
        "# from scripts import * # ????\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n",
        "\n",
        "# CUDA_LAUNCH_BLOCKING=\"1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qPNABu4sf2h"
      },
      "source": [
        "# **Classification Funcs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ikaADKdjsRrS"
      },
      "outputs": [],
      "source": [
        "def read_dataset(path):\n",
        "    # dataset = []\n",
        "    # for filename in tqdm(glob.iglob(path + '/*.png' , recursive=True) , desc = \"Reading\"):\n",
        "    #     # image_name = filename.split('/')[1] \n",
        "    #     # class_type = image_name.split('_')[0]\n",
        "    #     image_name = filename;\n",
        "    #     image = cv2.imread(filename)\n",
        "    #     image =  transforms.ToPILImage()(image)\n",
        "    #     image = transforms.Resize((224 , 224))(image)\n",
        "    #     image = transforms.ToTensor()(image)\n",
        "    #     dataset.append((image , int(class_type)))\n",
        "    # return dataset     \n",
        "    dataset = []\n",
        "    df = pd.read_csv (path+'_GroundTruth.csv')\n",
        "    df2 = pd.DataFrame(df, columns= ['image'])\n",
        "    df2 = df2.to_numpy();\n",
        "    df = pd.DataFrame(df, columns= ['MEL','NV','BCC','AKIEC','BKL','DF','VASC'])\n",
        "    df = df.to_numpy();\n",
        "    # if(len(df)>200):\n",
        "    #   df = df[1:5000];\n",
        "    for i,j in enumerate(df):\n",
        "      # print((i,j))\n",
        "      class_type = np.where(j)[0][0];\n",
        "      # print(class_type)\n",
        "      image = cv2.imread(path+'_Input/'+df2[i][0]+'.jpg')\n",
        "      # print(image.shape)\n",
        "      for t in range(3):\n",
        "        mi = image[:,:,t].min();\n",
        "        ma = image[:,:,t].max();\n",
        "        image[:,:,t] = (image[:,:,t]-mi)/(ma-mi)*255;\n",
        "        # mi = image[:,:,t].min();\n",
        "        # ma = image[:,:,t].max();\n",
        "        # print([mi, ma]);\n",
        "      image = cv2.resize(image, (224, 224));\n",
        "      # cv2_imshow(image)\n",
        "      # image = NLMDenoiser(image); # Denoising\n",
        "      # cv2_imshow(NLMDenoiser(image))\n",
        "      image =  transforms.ToPILImage()(image)\n",
        "      # image = transforms.Resize((299 , 299))(image)\n",
        "      # image = transforms.Resize((224 , 224))(image)\n",
        "      image = transforms.ToTensor()(image)\n",
        "      dataset.append((image , int(class_type)))\n",
        "      # break;\n",
        "    return dataset \n",
        "\n",
        "def read_dataset_transformation_all(path): \n",
        "    dataset = []\n",
        "    df = pd.read_csv (path+'_GroundTruth.csv')\n",
        "    df2 = pd.DataFrame(df, columns= ['image'])\n",
        "    df2 = df2.to_numpy();\n",
        "    df = pd.DataFrame(df, columns= ['MEL','NV','BCC','AKIEC','BKL','DF','VASC'])\n",
        "    df = df.to_numpy();\n",
        "    for i,j in enumerate(df):\n",
        "      class_type = np.where(j)[0][0];\n",
        "      image = cv2.imread(path+'_Input/'+df2[i][0]+'.jpg')\n",
        "      for t in range(3):\n",
        "        mi = image[:,:,t].min();\n",
        "        ma = image[:,:,t].max();\n",
        "        image[:,:,t] = (image[:,:,t]-mi)/(ma-mi)*255;\n",
        "      image =  transforms.ToPILImage()(image)\n",
        "      image = transforms.Resize((224 , 224))(image)\n",
        "      image = transforms.RandomHorizontalFlip()(image)\n",
        "      image = transforms.RandomAffine(degrees = 90, translate= (0.2 , 0.2))(image)\n",
        "      image = transforms.ToTensor()(image)\n",
        "      dataset.append((image , int(class_type)))\n",
        "    return dataset \n",
        "\n",
        "def transformation_all(dataset):\n",
        "    new_dataset = []\n",
        "    for image , label in dataset: \n",
        "        image = transforms.ToPILImage()(image)\n",
        "        # image = transforms.RandomHorizontalFlip()(image)\n",
        "        image = transforms.functional.hflip(image)\n",
        "        # image = transforms.RandomAffine(degrees = 90, translate= (0.2 , 0.2))(image)\n",
        "        image = transforms.ToTensor()(image)\n",
        "        new_dataset.append((image , label))\n",
        "    return new_dataset\n",
        "\n",
        "def NLMDenoiser(noisy):\n",
        "  # noisy = transforms.ToPILImage()(noisy)\n",
        "  # sigma_est = np.mean(estimate_sigma(noisy, channel_axis=-1))\n",
        "  # sigma_est = np.mean(estimate_sigma(noisy))\n",
        "  # patch_kw = dict(patch_size=500,      # 5x5 patches\n",
        "  #               patch_distance=600,  # 13x13 search area\n",
        "  #             )\n",
        "  #               # channel_axis=-1)\n",
        "  # denoise2_fast = denoise_nl_means(noisy, h=0.6 * sigma_est, sigma=sigma_est,\n",
        "  #                                fast_mode=True, **patch_kw)\n",
        "  # denoise2_fast = transforms.ToTensor()(denoise2_fast)\n",
        "  \n",
        "  # cv2_imshow(noisy)\n",
        "  # noisy = [np.uint8(np.clip(i,0,255)) for i in noisy]\n",
        "  # denoise2_fast = cv2.fastNlMeansDenoisingMulti(noisy, 2, 1, None, 4, 7, 35);\n",
        "  denoise2_fast = cv2.fastNlMeansDenoisingColored(noisy,None,10,10,7,21)\n",
        "  # cv2_imshow(denoise2_fast)\n",
        "  return denoise2_fast;\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "    if feature_extracting == False:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft\n",
        "\n",
        "def train_model(model, dataloaders, criterion, optimizer, scheduler = False, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.2 * loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        # print(outputs.shape)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                        # scheduler.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            if(phase=='val'):\n",
        "              scheduler.step(epoch_loss)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "    # Scheduler\n",
        "    # Hyperparameters\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    PATH = \"state_dict_model.pt\"\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "    return model, val_acc_history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVXXtOkP0ZfM"
      },
      "source": [
        "# **Read Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5_-FMgL0biL",
        "outputId": "50790bac-bdac-4717-8525-f0be0c0d2aa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10015\n",
            "193\n"
          ]
        }
      ],
      "source": [
        "csv_path = '';\n",
        "\n",
        "train_dataset = read_dataset('ISIC2018_Task3_Training')\n",
        "\n",
        "val_dataset = read_dataset('ISIC2018_Task3_Validation')\n",
        "\n",
        "# train_dataset_augmented = transformation_all(train_dataset);\n",
        "# train_dataset = train_dataset_augmented + train_dataset \n",
        "\n",
        "print(len(train_dataset))\n",
        "print(len(val_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHos047Ts76N"
      },
      "source": [
        "# **Train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZrLrqZUX-5c"
      },
      "outputs": [],
      "source": [
        "print(train_dataset[0][0].shape)\n",
        "print(len(train_dataset))\n",
        "print(train_dataset[0])\n",
        "print(next(iter(train_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oi1Ass5ks6p4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3d7cae4c34fa461497e60ec340eaa046",
            "8b66f358add249f18b553f735cef9b9d",
            "7633f001b65843a6afe87eab6a83bba8",
            "ad4ba1cf01b04d37a7b8483d3c269f85",
            "ddba54d893b34f2b97bd6b3ee4ef5cc4",
            "5623ea6ab32e45a08543cebebd5fc066",
            "48dc6003d21e4f8bb7a27579420a607a",
            "fc332605a40f4d639007f2d116218814",
            "bfd2a08f8a154e098eff0a79a1906853",
            "879f7a1e38f947d9928641d5c04a2c97",
            "c1957eed71b840d59ab85fc5d171e88f"
          ]
        },
        "outputId": "e1cc44b8-407b-454c-a07b-5b76c46369d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d7cae4c34fa461497e60ec340eaa046"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.8184 Acc: 0.7123\n",
            "val Loss: 0.7335 Acc: 0.7565\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.6777 Acc: 0.7559\n",
            "val Loss: 0.6763 Acc: 0.7461\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.5752 Acc: 0.7945\n",
            "val Loss: 0.5785 Acc: 0.7876\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.4499 Acc: 0.8401\n",
            "val Loss: 0.5925 Acc: 0.7927\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.3296 Acc: 0.8850\n",
            "val Loss: 0.7717 Acc: 0.7772\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.2272 Acc: 0.9221\n",
            "val Loss: 1.1179 Acc: 0.7202\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.1614 Acc: 0.9460\n",
            "val Loss: 0.7719 Acc: 0.7824\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.1245 Acc: 0.9587\n",
            "val Loss: 0.9619 Acc: 0.7668\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.0997 Acc: 0.9686\n",
            "val Loss: 0.8780 Acc: 0.7824\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.0975 Acc: 0.9671\n",
            "val Loss: 1.1595 Acc: 0.7876\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.0825 Acc: 0.9741\n",
            "val Loss: 0.8809 Acc: 0.7617\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.0700 Acc: 0.9784\n",
            "val Loss: 1.3246 Acc: 0.7150\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.0786 Acc: 0.9742\n",
            "val Loss: 0.9664 Acc: 0.7824\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0577 Acc: 0.9818\n",
            "Epoch 00014: reducing learning rate of group 0 to 5.0000e-05.\n",
            "val Loss: 1.1424 Acc: 0.7772\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.0242 Acc: 0.9933\n",
            "val Loss: 1.1476 Acc: 0.7565\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0145 Acc: 0.9963\n",
            "val Loss: 1.1209 Acc: 0.7565\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.0140 Acc: 0.9960\n",
            "val Loss: 1.1331 Acc: 0.7668\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.0185 Acc: 0.9945\n",
            "val Loss: 1.0639 Acc: 0.7720\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.0176 Acc: 0.9960\n",
            "val Loss: 1.0049 Acc: 0.7772\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.0085 Acc: 0.9979\n",
            "val Loss: 1.2241 Acc: 0.7617\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.0164 Acc: 0.9959\n",
            "val Loss: 1.1455 Acc: 0.7876\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.0141 Acc: 0.9960\n",
            "val Loss: 1.3698 Acc: 0.7617\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.0121 Acc: 0.9969\n",
            "val Loss: 1.3907 Acc: 0.7720\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.0128 Acc: 0.9957\n",
            "val Loss: 1.4632 Acc: 0.7513\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.0097 Acc: 0.9976\n",
            "Epoch 00025: reducing learning rate of group 0 to 2.5000e-05.\n",
            "val Loss: 1.3857 Acc: 0.7306\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.0078 Acc: 0.9982\n",
            "val Loss: 1.3262 Acc: 0.7720\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.0029 Acc: 0.9994\n",
            "val Loss: 1.3369 Acc: 0.7720\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.0020 Acc: 0.9995\n",
            "val Loss: 1.3689 Acc: 0.7668\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.0039 Acc: 0.9991\n",
            "val Loss: 1.2949 Acc: 0.7668\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.0031 Acc: 0.9994\n",
            "val Loss: 1.3209 Acc: 0.7668\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.0051 Acc: 0.9984\n",
            "val Loss: 1.4020 Acc: 0.7513\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.0046 Acc: 0.9991\n",
            "val Loss: 1.4736 Acc: 0.7461\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.0039 Acc: 0.9988\n",
            "val Loss: 1.4687 Acc: 0.7565\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.0023 Acc: 0.9995\n",
            "val Loss: 1.4217 Acc: 0.7617\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.0046 Acc: 0.9989\n",
            "val Loss: 1.5253 Acc: 0.7720\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.0028 Acc: 0.9994\n",
            "Epoch 00036: reducing learning rate of group 0 to 1.2500e-05.\n",
            "val Loss: 1.5517 Acc: 0.7617\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.0020 Acc: 0.9994\n",
            "val Loss: 1.5420 Acc: 0.7824\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.0013 Acc: 0.9996\n",
            "val Loss: 1.4998 Acc: 0.7617\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.0026 Acc: 0.9993\n",
            "val Loss: 1.3198 Acc: 0.7720\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.0007 Acc: 0.9999\n",
            "val Loss: 1.5797 Acc: 0.7617\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.0014 Acc: 0.9997\n",
            "val Loss: 1.5084 Acc: 0.7720\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.0007 Acc: 0.9998\n",
            "val Loss: 1.5262 Acc: 0.7668\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.0012 Acc: 0.9997\n",
            "val Loss: 1.4269 Acc: 0.7824\n",
            "\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.0007 Acc: 0.9998\n",
            "val Loss: 1.4048 Acc: 0.7565\n",
            "\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.0010 Acc: 0.9996\n",
            "val Loss: 1.4420 Acc: 0.7617\n",
            "\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.0025 Acc: 0.9995\n",
            "val Loss: 1.4643 Acc: 0.7772\n",
            "\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.0013 Acc: 0.9996\n",
            "Epoch 00047: reducing learning rate of group 0 to 6.2500e-06.\n",
            "val Loss: 1.3336 Acc: 0.7668\n",
            "\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.0015 Acc: 0.9997\n",
            "val Loss: 1.4169 Acc: 0.7772\n",
            "\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 0.0003 Acc: 1.0000\n",
            "val Loss: 1.4564 Acc: 0.7720\n",
            "\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 0.0006 Acc: 0.9999\n",
            "val Loss: 1.5151 Acc: 0.7668\n",
            "\n",
            "Training complete in 71m 36s\n",
            "Best val Acc: 0.792746\n"
          ]
        }
      ],
      "source": [
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"resnet\"\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 7\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "BATCH_SIZE = 5\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 50\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = False\n",
        "\n",
        "# Initialize the model for this run\n",
        "model = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "# Send the model to GPU\n",
        "model = model.to(device)\n",
        "\n",
        "# min max normalization\n",
        "# augmentation\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
        "# lambda1 = lambda epoch: 0.65 ** epoch\n",
        "# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=10, threshold=1e-8, verbose=True)\n",
        "\n",
        "# optimized = SGD\n",
        "# optimized = SGD Momentum = 0.9\n",
        "# scheduler\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "dataloaders_dict = {'train' : train_loader , 'val': val_loader }\n",
        "\n",
        "\n",
        "model , val_acc = train_model(model, dataloaders_dict, criterion, optimizer, scheduler , num_epochs = num_epochs , is_inception = (model_name==\"inception\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Save Model**"
      ],
      "metadata": {
        "id": "QD2V0ZBGHUtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'Model.pt')"
      ],
      "metadata": {
        "id": "0ryLaMtoHXby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Model**"
      ],
      "metadata": {
        "id": "2vCG3iWEKHKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restart runtime first."
      ],
      "metadata": {
        "id": "4NpiYVsrLp1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = transformation_all(val_dataset)"
      ],
      "metadata": {
        "id": "c0bUj1B0cnCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('Model.pt')\n",
        "csv_path = '';\n",
        "\n",
        "train_dataset = read_dataset_transformation_all('ISIC2018_Task3_Training')\n",
        "\n",
        "val_dataset = read_dataset('ISIC2018_Task3_Validation')\n",
        "\n",
        "print(len(train_dataset))\n",
        "print(len(val_dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-6i9gb4KgOY",
        "outputId": "4263a459-658f-4745-f6e8-80b715d7f85a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10015\n",
            "193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"resnet\"\n",
        "num_classes = 7\n",
        "BATCH_SIZE = 5\n",
        "num_epochs = 50\n",
        "feature_extract = False\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=10, threshold=1e-8, verbose=True)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "dataloaders_dict = {'train' : train_loader , 'val': val_loader }\n",
        "\n",
        "model , val_acc = train_model(model, dataloaders_dict, criterion, optimizer, scheduler , num_epochs = num_epochs , is_inception = (model_name==\"inception\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qExbsS9jMJvd",
        "outputId": "802ae89f-34ca-4e9d-c1bb-4bc14358b470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.6661 Acc: 0.7861\n",
            "val Loss: 0.5809 Acc: 0.8187\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.3970 Acc: 0.8622\n",
            "val Loss: 0.5510 Acc: 0.8342\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.2333 Acc: 0.9222\n",
            "val Loss: 0.6923 Acc: 0.8497\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.1317 Acc: 0.9571\n",
            "val Loss: 0.9683 Acc: 0.7772\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.0914 Acc: 0.9721\n",
            "val Loss: 1.0680 Acc: 0.8135\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.0807 Acc: 0.9743\n",
            "val Loss: 0.9495 Acc: 0.8601\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.0732 Acc: 0.9800\n",
            "val Loss: 0.5922 Acc: 0.8446\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.0748 Acc: 0.9769\n",
            "val Loss: 0.7485 Acc: 0.8187\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.0498 Acc: 0.9832\n",
            "val Loss: 0.9438 Acc: 0.8342\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.0531 Acc: 0.9837\n",
            "val Loss: 0.9222 Acc: 0.8549\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.0456 Acc: 0.9851\n",
            "val Loss: 1.0862 Acc: 0.7979\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.0537 Acc: 0.9830\n",
            "val Loss: 0.8385 Acc: 0.8497\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.0412 Acc: 0.9870\n",
            "Epoch 00013: reducing learning rate of group 0 to 5.0000e-05.\n",
            "val Loss: 1.1908 Acc: 0.8031\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0206 Acc: 0.9954\n",
            "val Loss: 1.1384 Acc: 0.8031\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.0099 Acc: 0.9967\n",
            "val Loss: 1.1592 Acc: 0.8290\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0105 Acc: 0.9971\n",
            "val Loss: 0.9212 Acc: 0.8290\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.0055 Acc: 0.9984\n",
            "val Loss: 0.9470 Acc: 0.8238\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.0132 Acc: 0.9959\n",
            "val Loss: 0.9088 Acc: 0.8394\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.0085 Acc: 0.9977\n",
            "val Loss: 1.0519 Acc: 0.8135\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.0086 Acc: 0.9981\n",
            "val Loss: 1.1801 Acc: 0.8290\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.0107 Acc: 0.9967\n",
            "val Loss: 1.2007 Acc: 0.8083\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.0067 Acc: 0.9986\n",
            "val Loss: 1.1652 Acc: 0.8394\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.0077 Acc: 0.9977\n",
            "val Loss: 1.0834 Acc: 0.8290\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.0087 Acc: 0.9974\n",
            "Epoch 00024: reducing learning rate of group 0 to 2.5000e-05.\n",
            "val Loss: 1.1954 Acc: 0.8342\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.0078 Acc: 0.9983\n",
            "val Loss: 1.2351 Acc: 0.8238\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.0013 Acc: 0.9999\n",
            "val Loss: 1.2420 Acc: 0.8187\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.0023 Acc: 0.9997\n",
            "val Loss: 1.1528 Acc: 0.8135\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.0023 Acc: 0.9994\n",
            "val Loss: 1.1911 Acc: 0.8238\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.0020 Acc: 0.9996\n",
            "val Loss: 1.0588 Acc: 0.8238\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.0026 Acc: 0.9992\n",
            "val Loss: 1.1013 Acc: 0.8446\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.0006 Acc: 1.0000\n",
            "val Loss: 1.2298 Acc: 0.8187\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.0004 Acc: 0.9999\n",
            "val Loss: 1.2338 Acc: 0.8238\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.0026 Acc: 0.9996\n",
            "val Loss: 1.2612 Acc: 0.8342\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.0022 Acc: 0.9994\n",
            "val Loss: 1.0355 Acc: 0.8290\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.0030 Acc: 0.9991\n",
            "Epoch 00035: reducing learning rate of group 0 to 1.2500e-05.\n",
            "val Loss: 1.2701 Acc: 0.8549\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.0012 Acc: 0.9997\n",
            "val Loss: 1.1603 Acc: 0.8549\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.0006 Acc: 0.9998\n",
            "val Loss: 1.2725 Acc: 0.8135\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.0006 Acc: 0.9998\n",
            "val Loss: 1.1233 Acc: 0.8394\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.0003 Acc: 0.9999\n",
            "val Loss: 1.0620 Acc: 0.8601\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.0007 Acc: 0.9998\n",
            "val Loss: 1.0235 Acc: 0.8756\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.0018 Acc: 0.9998\n",
            "val Loss: 1.2414 Acc: 0.8238\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.0008 Acc: 0.9998\n",
            "val Loss: 1.1878 Acc: 0.8394\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.0004 Acc: 0.9998\n",
            "val Loss: 1.2611 Acc: 0.8342\n",
            "\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.0002 Acc: 1.0000\n",
            "val Loss: 1.1783 Acc: 0.8446\n",
            "\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.0004 Acc: 0.9999\n",
            "val Loss: 1.3187 Acc: 0.8290\n",
            "\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch 00046: reducing learning rate of group 0 to 6.2500e-06.\n",
            "val Loss: 1.2849 Acc: 0.8394\n",
            "\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.0005 Acc: 0.9999\n",
            "val Loss: 1.2238 Acc: 0.8394\n",
            "\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.0009 Acc: 0.9997\n",
            "val Loss: 1.3508 Acc: 0.8342\n",
            "\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 0.0016 Acc: 0.9995\n",
            "val Loss: 1.2413 Acc: 0.8394\n",
            "\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 0.0006 Acc: 0.9998\n",
            "val Loss: 1.3460 Acc: 0.8238\n",
            "\n",
            "Training complete in 44m 41s\n",
            "Best val Acc: 0.875648\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "oIhvqNOlkIXH",
        "943VW21vsVTj",
        "0qPNABu4sf2h",
        "XVXXtOkP0ZfM",
        "mHos047Ts76N",
        "QD2V0ZBGHUtq",
        "2vCG3iWEKHKc"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3d7cae4c34fa461497e60ec340eaa046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b66f358add249f18b553f735cef9b9d",
              "IPY_MODEL_7633f001b65843a6afe87eab6a83bba8",
              "IPY_MODEL_ad4ba1cf01b04d37a7b8483d3c269f85"
            ],
            "layout": "IPY_MODEL_ddba54d893b34f2b97bd6b3ee4ef5cc4"
          }
        },
        "8b66f358add249f18b553f735cef9b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5623ea6ab32e45a08543cebebd5fc066",
            "placeholder": "​",
            "style": "IPY_MODEL_48dc6003d21e4f8bb7a27579420a607a",
            "value": "100%"
          }
        },
        "7633f001b65843a6afe87eab6a83bba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc332605a40f4d639007f2d116218814",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfd2a08f8a154e098eff0a79a1906853",
            "value": 46830571
          }
        },
        "ad4ba1cf01b04d37a7b8483d3c269f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_879f7a1e38f947d9928641d5c04a2c97",
            "placeholder": "​",
            "style": "IPY_MODEL_c1957eed71b840d59ab85fc5d171e88f",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 185MB/s]"
          }
        },
        "ddba54d893b34f2b97bd6b3ee4ef5cc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5623ea6ab32e45a08543cebebd5fc066": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48dc6003d21e4f8bb7a27579420a607a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc332605a40f4d639007f2d116218814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfd2a08f8a154e098eff0a79a1906853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "879f7a1e38f947d9928641d5c04a2c97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1957eed71b840d59ab85fc5d171e88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}